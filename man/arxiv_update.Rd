% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/arxiv_update.R
\name{arxiv_update}
\alias{arxiv_update}
\title{Update locally stored arXiv dataset for a given query}
\usage{
arxiv_update(
  search_query,
  csv_path = NULL,
  meta_path = NULL,
  max_results = 200L,
  sort_by = c("submittedDate", "lastUpdatedDate", "relevance"),
  sort_order = c("descending", "ascending"),
  user_agent = "arxivThreatIntel (R; contact: <your_email>)",
  timeout_sec = 30L
)
}
\arguments{
\item{search_query}{Character scalar. arXiv API search query.}

\item{csv_path}{Optional CSV file path for cached records.}

\item{meta_path}{Optional JSON file path for metadata.}

\item{max_results}{Integer. How many of the newest records to fetch each update.}

\item{sort_by, sort_order}{Passed to arxiv_fetch().}

\item{user_agent, timeout_sec}{Passed to arxiv_fetch().}
}
\value{
A list with:
\itemize{
\item records: tibble of merged records
\item added: integer, how many new unique records were added
\item csv_path: path where records were saved
\item meta_path: path where metadata was saved
}
}
\description{
Loads existing records from CSV, fetches latest records from arXiv API,
merges them, removes duplicates, and saves back to CSV. Also stores update metadata.

Update strategy:
\itemize{
\item Always fetch first N records (max_results) sorted by submittedDate desc.
\item Merge with existing cache and deduplicate by arXiv id.
This is robust and simple. It does not rely on arXiv "since" filtering.
}
}
